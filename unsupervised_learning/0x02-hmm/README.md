# Hidden Markov Models

## Specializations - Machine Learning â€• Unsupervised Learning

## Description

* This repository contains Hidden Markov Models exercises

## Learning Objectives

**Understand:**

* What is the Markov property?
* What is a Markov chain?
* What is a state?
* What is a transition probability/matrix?
* What is a stationary state?
* What is a regular Markov chain?
* How to determine if a transition matrix is regular
* What is an absorbing state?
* What is a transient state?
* What is a recurrent state?
* What is an absorbing Markov chain?
* What is a Hidden Markov Model?
* What is a hidden state?
* What is an observation?
* What is an emission probability/matrix?
* What is a Trellis diagram?
* What is the Forward algorithm and how do you implement it?
* What is decoding?
* What is the Viterbi algorithm and how do you implement it?
* What is the Forward-Backward algorithm and how do you implement it?
* What is the Baum-Welch algorithm and how do you implement it?


## Dependencies
```
Python 3.5
numpy 1.15
```

## Repo content

* **Main Folder that contains all main of the following tasks:**

| Task | Description |
| --- | --- |
|**0. Markov Chain**| determines the probability of a markov chain being in a particular state after a specified number of iterations
|**1. Regular Chains**| determines the steady state probabilities of a regular markov chain
|**2. Absorbing Chains**| determines if a markov chain is absorbing
|**3. The Forward Algorithm**| performs the forward algorithm for a hidden markov model
|**4. The Viretbi Algorithm**| calculates the most likely sequence of hidden states for a hidden markov model
|**5. The Backward Algorithm**|  performs the backward algorithm for a hidden markov model
|**6. The Baum-Welch Algorithm**|  performs the Baum-Welch algorithm for a hidden markov model

## Usage
* Clone the repo and execute the main files

## Author
- [Cristian G](https://github.com/cristian-fg)

## License
[MIT](https://choosealicense.com/licenses/mit/)
