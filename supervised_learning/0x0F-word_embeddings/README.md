# Natural Language Processing - Word Embeddings

## Specializations - Machine Learning â€• Supervised Learning

## Description

* This repository contains some Natural Language Processing - Word Embeddings exercises

## Learning Objectives

**Understand:**

* What is natural language processing?
* What is a word embedding?
* What is bag of words?
* What is TF-IDF?
* What is CBOW?
* What is a skip-gram?
* What is an n-gram?
* What is negative sampling?
* What is word2vec, GloVe, fastText, ELMo?


## Dependencies
```
Python 3.5
numpy 1.15
tensorflow 1.12
Gensim 3.8.x
Keras 2.2.5
```

## Repo content

* **Main Folder that contains all main of the following tasks:**

| Task | Description |
| --- | --- |
|**0. Bag Of Words**| creates a bag of words embedding matrix
|**1. TF-IDF**| creates a TF-IDF embedding
|**2. Train Word2Vec**| creates and trains a gensim word2vec model
|**3. Extract Word2Vec**| converts a gensim word2vec model to a keras Embedding layer
|**4. FastText**| creates and trains a genism fastText model
|**5. ELMo**| answer txt file

## Usage
* Clone the repo and execute the main files

## Author
- [Cristian G](https://github.com/cristian-fg)

## License
[MIT](https://choosealicense.com/licenses/mit/)
